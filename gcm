from google.cloud import monitoring_v3
from datetime import datetime, timedelta
import pytz

# Set your project ID
project_id = "fkp-specter-pubsub"
client = monitoring_v3.MetricServiceClient()
project_name = f"projects/{project_id}"

# Define time interval (last 13 minutes to get ~13 data points)
end_time = datetime.utcnow().replace(tzinfo=pytz.UTC)
start_time = end_time - timedelta(minutes=13)

interval = monitoring_v3.TimeInterval({
    "end_time": {"seconds": int(end_time.timestamp())},
    "start_time": {"seconds": int(start_time.timestamp())},
})

# Define aggregation: 1-minute alignment, align to rate
aggregation = monitoring_v3.Aggregation({
    "alignment_period": {"seconds": 60},
    "per_series_aligner": monitoring_v3.Aggregation.Aligner.ALIGN_RATE,
    "cross_series_reducer": monitoring_v3.Aggregation.Reducer.REDUCE_NONE,
})

# Define the metric type
metric_type = "pubsub.googleapis.com/topic/byte_cost"

# Collect values with timestamps
data_points = []

# Make the request
for time_series in client.list_time_series(
    request={
        "name": project_name,
        "filter": f'metric.type = "{metric_type}"',
        "interval": interval,
        "aggregation": aggregation,
        "view": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,
    }
):
    for point in time_series.points:
        timestamp = point.interval.end_time
        value = point.value.double_value
        # Convert timestamp to ISO format string
        ts_str = timestamp.ToDatetime().isoformat()
        data_points.append((ts_str, value))

# Reverse to chronological order
data_points = list(reversed(data_points))

# Print the results
for ts, val in data_points:
    print(f"{ts}  ->  {val:.6f}")
